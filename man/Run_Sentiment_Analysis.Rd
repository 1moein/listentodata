% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Run_Sentiment_Analysis.R
\name{Run_Sentiment_Analysis}
\alias{Run_Sentiment_Analysis}
\title{Sentiment Analysis}
\usage{
Run_Sentiment_Analysis(
  mydata,
  words2remove,
  stemthis = FALSE,
  wcmf = 5,
  mostfrequent = 25
)
}
\arguments{
\item{mydata}{A .csv file to be analyzed. Each line must be a separate text: a tweet, review, or document.}

\item{words2remove}{A vector of words to remove from the analysis because of their irrelevance.}

\item{stemthis}{To stem the documents or not to stem: default = FALSE, you can set it to TRUE}

\item{wcmf}{Word Cloud Minimum Frequency: default = 5. Words with frequencies lower than this amount will not be displayed in the word cloud}

\item{mostfrequent}{Number of most frequent words to display, default = 25}
}
\description{
This function conducts a Sentiment analysis on data from a csv file, comprised of one column of text. Each cell in that column  must be an independent tweet, review, or document.
}
\examples{
\dontrun{
# You need to have one csv file containing one column of text with a column header.
# Each cell in this file after the first cell will be a tweet, review, or document...
# The next few lines prepare and run the analysis.
# This is the sample code to be copied and used in a new R Script:
library(listentodata)
clear_console()
mydata = load_csv_data()
words2remove = c("toremvoe1", "toremove2")
stemthis = FALSE
wcmf = 5 # Word Cloud Minimum Frequency: default = 5
mostfrequent = 25
Run_Sentiment_Analysis(mydata, words2remove, stemthis, wcmf, mostfrequent)
}
}
