% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Run_Sentiment_Analysis.R
\name{Run_Sentiment_Analysis}
\alias{Run_Sentiment_Analysis}
\title{Sentiment Analysis}
\usage{
Run_Sentiment_Analysis(
  textdata,
  words2remove,
  stemthis = FALSE,
  wcmf = 5,
  mostfrequent = 25
)
}
\arguments{
\item{textdata}{A .txt Text file to be analyzed. Each line must be an independent text: a tweet, review, or document.}

\item{words2remove}{A vector of words to remove from the analysis because of their irrelevance.}

\item{stemthis}{To stem the documents or not to stem: default = FALSE, you can set it to TRUE}

\item{wcmf}{Word Cloud Minimum Frequency: default = 5. Words with frequencies lower than this amount will not be displayed in the word cloud}

\item{mostfrequent}{Number of most frequent words to display, default = 25}
}
\description{
This function conducts a Sentiment analysis on data from a text file. Each row must be an independent tweet, review, or document.
}
\examples{
\dontrun{
# You need to have one csv file containing one columne of text.
# Each cell in this file will be a tweet, review, or document...
# In Excel, press CTRL/Command H, to open the search and replace diaglog.
# With your cursor in the Find What box, press CTRL/Command J, then click Replace All.
# The above steps search for and replace all line breaks in your document which is
# necessary as a preparation step for this analysis.
# The next few lines prepare and run the analysis.
# This is the sample code to be copied and used in a new R Script:
library(listentodata)
clear_console()
textdata = load_csv_data()
words2remove = c("toremvoe1", "toremove2")
stemthis = FALSE
wcmf = 5 # Word Cloud Minimum Frequency: default = 5
mostfrequent = 25
Run_Sentiment_Analysis(textdata, stemthis, wcmf, mostfrequent)
}
}
